---
layout: page
title: Session 5
permalink: /materials/session5
---

<div align="center">
    <img src="../sessions/assets/session5.png" width="70%">
</div>

### Introduction

Based on the discussions of vast capabilities of LLMs on various tasks in the previous classes, it might be tempting to say that LLMs *understand* the tasks and, more broadly, the world. But what does it really mean to **understand** something? Building on the question whether LLMs might be human-like models of language production, processing or learning, what is an **explanatory model**, and can LLMs count as such? These are far from trivial questions that have been discussed in fields like philosophy, cognitive science and philosophy of science for many years. 

Therefore, in this session, we set out to discuss the implications of LLMs on (philosophy of) cognitive science, with a particular focus on understanding and explanations. First, key theoretical approaches to these concepts will be highlighted, and then we will see how different aspects of LLMs' understanding have been inspected in recent studies. Then, we will switch the point of view and look at LLMs from the perspective of usefully engineered tools which arguably contain rich contents mirroring many aspects of human language use. We will dive into the recently sky-rocketed framework *LangChain* and get ideas about how to make the most of LLMs' capabilities in creative ways, and how these could be embedded in scientific explanatory models.

Therefore, learning goals for this session are:
* understand understanding
  * of language
  * of the world
  * of models
* being able to identify important aspects of an explanatory theory in science
* get acquainted with hybrid explanatory models
* dive into LLM chains, agents & LangChain (hands on) 

The high-level goals of this session are to enable ourselves to think about explanatory and usefully engineered models and how these could complement each other, as well as critically evaluate what the relation between LLMs and understanding might be. 
The materials for the hands-on part are available in the Code section below. These are meant to be a potential boilerplate / inspiration for class projects.

### Slides

<object data="slides/05-Philo-Cogsci-Models.pdf" type="application/pdf" width="100%" height="500px"> 
    <p>Unable to display PDF file. <a href="slides/05-Philo-Cogsci-Models.pdf">Download</a> instead.</p>
</object>

### Code

[Python script](code/04-get-gpt-surprisals.py)...

[Data](code/data/grammaticality_tests.csv)...


### Further materials

* LangChain tutorials
* [Generative agents paper]()
* [Tree chain]
* 